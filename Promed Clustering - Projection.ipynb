{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, matplotlib.cm as cm\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from geopy.distance import great_circle\n",
    "from pymongo import MongoClient\n",
    "import calendar\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client['promed']\n",
    "posts = db.posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use shapefile bundled with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gets a unique list of diseases\n",
    "def get_disease_list():\n",
    "#   diseaseNames = posts.distinct('subject.diseaseLabels')\n",
    "#   return sorted(diseaseNames)\n",
    "    return ['Anthrax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the articles that have the current disease in it's \"diseaseLabels\" array\n",
    "def get_articles(disease):\n",
    "#   print('get articles', disease)\n",
    "  articles = posts.find({ \n",
    "    'zoomLat': {'$ne': None}, \n",
    "    'zoomLon': {'$ne': None}, \n",
    "    'subject.diseaseLabels':{'$not':{'$size': 0}}, \n",
    "    'subject.diseaseLabels': {'$in': [disease]}\n",
    "    },\n",
    "    {'subject.diseaseLabels':1,\n",
    "    'zoomLat': 1, \n",
    "    'zoomLon': 1, \n",
    "    'sourceDate': 1, \n",
    "    'promedDate': 1}\n",
    "  ).limit(300)\n",
    "  articles = list(articles);\n",
    "  for article in articles:\n",
    "    try:\n",
    "        # not all articles have a sourceDate so fall back to promedDate if missing.\n",
    "        date = article.get('sourceDate') or article.get('promedDate')\n",
    "        # convert date object to timestamp so DBSCAN can handle it\n",
    "        article['sourceDate'] = calendar.timegm(date.timetuple())/10000000.0\n",
    "        # convert disease labels array to single disease name\n",
    "        article['subject'] = article['subject']['diseaseLabels'][0]\n",
    "        article['zoomLat'] = float(article['zoomLat'])\n",
    "        article['zoomLon'] = float(article['zoomLon'])\n",
    "    except Exception as e:\n",
    "        print(\"Problem parsing article:\", article)\n",
    "        print(e)\n",
    "        raise\n",
    "#   print(sorted([x['sourceDate'] for x in articles]))\n",
    "\n",
    "  return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_points_projection(df):\n",
    "    # create a new geopandas geodataframe from the point data\n",
    "    points = gpd.GeoDataFrame(df)\n",
    "     # create a geometry column in our point data set for geopandas to use\n",
    "    points['geometry'] = points.apply(lambda item: Point(item['zoomLon'], item['zoomLat']), axis=1)\n",
    "    points.crs = world.crs\n",
    "    return points\n",
    "\n",
    "def project_map(pointList):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_aspect('equal')\n",
    "    world.plot(ax=ax, color='white', edgecolor='#cccccc')\n",
    "    \n",
    "#     Sort by length of cluster\n",
    "    pointList.sort(lambda x,y: cmp(len(x), len(y)))\n",
    "    \n",
    "#     Colormaps: http://matplotlib.org/users/colormaps.html\n",
    "    cmap = cm.get_cmap('plasma')\n",
    "    for points in pointList:\n",
    "        color = cmap(len(points)/float(7))\n",
    "        points.plot(ax=ax, marker='o', color=color, markersize=5)\n",
    "\n",
    "#     Add colorbar\n",
    "    vmin, vmax = 1, 7\n",
    "    fig = ax.get_figure()\n",
    "    cax = fig.add_axes([1, 0.21, 0.03, 0.61])\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    sm._A = []\n",
    "    cbar = fig.colorbar(sm, cax=cax, ticks=[1, 3, 5, 7])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single step clustering on timestamp/lat/long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "How do I determine the optimal `eps` value here?\n",
    "\n",
    "How should I take into account the third dimension (timestamp) when determining the `eps` value?  When it was only lat long the values were in similar ranges (-90 -> 90 and -180 -> 180) but with the timestamp values are much larger (ex: `9433152000`) which makes me thing that you will never get two timestamps in the same neighborhood if you have and eps value of, say, 2.  If I begin dividing the timestamp value by 10,000,000 it goes into a similar range for lat/long - is this something I should consider doing?\n",
    "\n",
    "Is it possible to specify dimensions for a sphereoid to define the `eps`?  It seems like there are a lot of situations where you wouldn't want a perfectly simetrical shape defining the neighborhood.\n",
    "\n",
    "How would I go about visualizing 3d data?  4d?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster(data, fields, eps=2):\n",
    "#     print(type(data))\n",
    "    if type(data) is not np.ndarray:\n",
    "#         print('convert....')\n",
    "        data = data.as_matrix(columns=fields)\n",
    "#     print(type(data))\n",
    "    #   coordinates = df.as_matrix(columns=['zoomLon', 'zoomLat'])\n",
    "    dbsc = DBSCAN(eps=eps, min_samples=1, algorithm='ball_tree').fit(data)\n",
    "    core_samples_mask = np.zeros_like(dbsc.labels_, dtype=bool)\n",
    "    core_samples_mask[dbsc.core_sample_indices_] = True\n",
    "    cluster_labels = dbsc.labels_\n",
    "    num_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "    clusters = pd.Series([data[cluster_labels == n] for n in range(num_clusters)])\n",
    "#     print('Number of clusters: {}'.format(num_clusters))\n",
    "#     for cluster in clusters:\n",
    "#         print(cluster[:])\n",
    "#     print('***********')\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_cluster(data, fields):\n",
    "    kms_per_radian = 6371.0088\n",
    "    eps = 1.5 / kms_per_radian\n",
    "#     print(\"distance data:\")\n",
    "#     print(np.radians(data[fields]))\n",
    "    dbsc = DBSCAN(eps=eps, min_samples=1, algorithm='ball_tree', metric='haversine').fit(np.radians(data[fields]))\n",
    "    core_samples_mask = np.zeros_like(dbsc.labels_, dtype=bool)\n",
    "    core_samples_mask[dbsc.core_sample_indices_] = True\n",
    "    cluster_labels = dbsc.labels_\n",
    "    num_clusters = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "    clusters = pd.Series([data[cluster_labels == n] for n in range(num_clusters)])\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_single_step(df):\n",
    "    cluster(df,['zoomLon', 'zoomLat', 'sourceDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two step temporal/spatial clustering\n",
    "First cluster on times only.  After that cluster on lat/long great circle distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_two_step(df):\n",
    "    # perform temporal clustering\n",
    "    temporalClusters = cluster(df,['sourceDate'], .1) # eps of .1 ~ 8 days\n",
    "\n",
    "    allClusterPoints = []\n",
    "    for temporalCluster in temporalClusters:\n",
    "        subSet = df['sourceDate'].isin(temporalCluster.flatten())\n",
    "        clusterArticles = df.loc[subSet][['sourceDate','zoomLat','zoomLon']]\n",
    "\n",
    "#         perform clustering on the articles in that cluster based on the lat/long great circle distance\n",
    "        spacialTemporalClusters = distance_cluster(clusterArticles, ['zoomLat', 'zoomLon'])\n",
    "\n",
    "#         record point data for the cluster\n",
    "        pointList = []\n",
    "        for spacialCluster in spacialTemporalClusters:\n",
    "            clusterPoints = get_points_projection(spacialCluster)\n",
    "            pointList.append(clusterPoints)\n",
    "            allClusterPoints.append(clusterPoints)\n",
    "        \n",
    "#         Project to map and print columns\n",
    "        project_map(pointList)\n",
    "        for spacialCluster in spacialTemporalClusters:\n",
    "            print(spacialCluster[['sourceDate','zoomLat','zoomLon']])\n",
    "\n",
    "#     Project all layers into a map. Warning: heavy.\n",
    "#     print('\\n\\n')\n",
    "#     print(\"--------------------------------------------------------------------------------\")\n",
    "#     print(\"--- All recorded points --------------------------------------------------------\")\n",
    "#     print(\"--------------------------------------------------------------------------------\")\n",
    "#     project_map(allClusterPoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diseaseList = get_disease_list()\n",
    "# for each disease get a list of articles and cluster them\n",
    "df = []\n",
    "startTime = time.time()\n",
    "for disease in diseaseList:\n",
    "    articleList = list(get_articles(disease))\n",
    "    print(\"--------------------------------------------------------------------------------\")\n",
    "    print(\"{0} articles for {1}\".format(len(articleList), disease))\n",
    "    df = pd.DataFrame(articleList)\n",
    "#     cluster_single_step(df)\n",
    "    cluster_two_step(df)\n",
    "\n",
    "print(\"--- FINISHED -------------------------------------------------------------------\")\n",
    "print(\"Total run time: {0:.1f}s\".format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "What would be the next steps?  How do we determine which cluster future articles fall into?  Do I just re-run this with all the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
